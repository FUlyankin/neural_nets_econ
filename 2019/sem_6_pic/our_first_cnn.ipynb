{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наша первая свёрточная нейросеть \n",
    "\n",
    "Пришло время построить нашу первую свёрточную нейросеть. Будем использовать для этого датасет [fashion MNIST.](https://www.cs.toronto.edu/~kriz/cifar.html) Набор данных включает в себя изображения рукописных цифр.  \n",
    "\n",
    "<img src=\"https://pbs.twimg.com/media/DVhOyJ1XkAACKqT.jpg\" style=\"width:70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "keras, L = tf.keras, tf.keras.layers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Смотрим на данные \n",
    "\n",
    "Скачаеми приготовим данные. Буквально через минуту в наших руках окажутся $60 000$ картинок размера $28 \\times 28$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Отнормировали данные к отрезку [0;1]\n",
    "X_train = X_train/ 255.\n",
    "X_test = X_test/ 255.\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train samples:\", X_train.shape, y_train.shape)\n",
    "print(\"Test samples:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем несколько рандомных картинок из тренировочной выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 8\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols, 2.5 * rows))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_train))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(X_train[random_index, :], cmap = 'gray')\n",
    "        ax.set_xlabel(class_names[y_train[random_index]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Выбираем для нашей нейросети архитектуру\n",
    "\n",
    "Свёрточная нейронная сеть строится из нескольких разных типов слоёв: \n",
    "\n",
    "* [Conv2D](https://keras.io/layers/convolutional/#conv2d) - Конволюция:\n",
    "    - **filters**: число выходных каналов; \n",
    "    - **kernel_size**: размер окна для свёртки;\n",
    "    - **padding**: padding=\"same\" добавляет нулевую каёмку по краям картинки, чтбы после свёртки размеры картинки не изменялись; padding='valid' ничего не добавляет;\n",
    "    - **activation**: \"relu\", \"tanh\", etc.\n",
    "    - **input_shape**: размер входа\n",
    "* [MaxPooling2D](https://keras.io/layers/pooling/#maxpooling2d) - макспулинг\n",
    "* [Flatten](https://keras.io/layers/core/#flatten) - разворачивает картинку в вектор \n",
    "* [Dense](https://keras.io/layers/core/#dense) - полносвязный слой (fully-connected layer)\n",
    "* [Activation](https://keras.io/layers/core/#activation) - функция активации\n",
    "* [LeakyReLU](https://keras.io/layers/advanced-activations/#leakyrelu) - leaky relu активация\n",
    "* [Dropout](https://keras.io/layers/core/#dropout) - дропаут.\n",
    "\n",
    "\n",
    "В модели, которую мы определим ниже, на вход будет идти тензоры размера __(None, 28, 28, 1)__ и __(None, 10)__. На выходе мы будем получать вероятноть того, что объект относится к конкретному классу. Разменость __None__ заготовлена для размерности батча. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Полносвязная сетка \n",
    "\n",
    "Соберём полносвязную сетку с нашей предыдущей пары/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_1 = Sequential( )\n",
    "\n",
    "model_1.add(L.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "model_1.add(L.Dense(64))\n",
    "model_1.add(L.BatchNormalization()) \n",
    "model_1.add(L.Activation('relu'))\n",
    "\n",
    "model_1.add(L.Dense(32))\n",
    "model_1.add(L.BatchNormalization()) \n",
    "model_1.add(L.Activation('relu'))\n",
    "\n",
    "model_1.add(L.Dense(16))\n",
    "model_1.add(L.BatchNormalization()) \n",
    "model_1.add(L.Activation('relu'))\n",
    "\n",
    "model_1.add(L.Dense(10, activation='softmax'))\n",
    "\n",
    "model_1.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "hist = model_1.fit(X_train, y_train, validation_split= 0.2,\n",
    "                        batch_size=500, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['Train loss', 'Validation loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoss, Accuracy = \", model_1.evaluate(X_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Посмотрите на качество получившейся модели. Вернитесь по коду вверх и раскоментируйте строки, где картинки нормируются к отрезку $[0;1]$. Переобучите сетку. Что произошло с качеством? \n",
    "* Теперь попробуйте использовать в качестве функции активации линейную функцию. Что произошло с качеством модели?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть, где именно сетка ошибается. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_1.predict_classes(X_test)\n",
    "errors =  y_pred != y_test\n",
    "\n",
    "# срежем только наблюдения, где была ошибка вместе с метками\n",
    "X_err = X_test[errors]\n",
    "y_err = y_test[errors]\n",
    "y_pred = y_pred[errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 4\n",
    "rows = 4\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 4 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_err))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.imshow(X_err[random_index, : ], cmap='gray')\n",
    "        ax.set_title('real_class: {} \\n  predict class: {}'.format(class_names[y_err[random_index]], \n",
    "                                                                   class_names[y_pred[random_index]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Свёрточная сетка \n",
    "\n",
    "Во-первых, нужно в явном виде указать, что у нас в изображениях один канал. Иначе питон будет ругаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:,:,:,np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:,:,:,np.newaxis]\n",
    "X_test = X_test[:,:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте соберём свёртоную сеть: \n",
    "\n",
    "* Свёртка с ядром $5 \\times 5$, same padding и $32$ каналами\n",
    "* ReLU\n",
    "* Макспулинг размера $2 \\times 2$\n",
    "* Свёртка с ядром $5 \\times 5$ и $16$ каналами  и same padding\n",
    "* ReLU\n",
    "* Макспулинг размера $2 \\times 2$ с шагом (strides) $2$ по обеим осям \n",
    "* Дальше сделайте `Flatten` и сделайте два полносвязных слоя с ReLU и $120$ и $60$ нейронами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# \n",
    "#  Ваша LeNet сетка :) \n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['Train loss', 'Validation loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoss, Accuracy = \", model_2.evaluate(X_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, точность довольно сильно подскочила. Попробуйте поиграться числом параметров и слоёв так, чтобы их стало меньше, а качество сетки стало лучше. Попробуйте обучать нейросетку большее количество эпох. \n",
    "\n",
    "Снова посмотрим на ошибки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(X_test, axis=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_2.predict_classes(X_test)\n",
    "errors =  y_pred != y_test\n",
    "\n",
    "X_err = np.squeeze(X_test[errors], axis=3)\n",
    "y_err = y_test[errors]\n",
    "y_pred = y_pred[errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 4\n",
    "rows = 4\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 4 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_err))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.imshow(X_err[random_index, : ], cmap='gray')\n",
    "        ax.set_title('real_class: {} \\n  predict class: {}'.format(class_names[y_err[random_index]], \n",
    "                                                                   class_names[y_pred[random_index]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так, кстати говоря, выглядят ошибки аналогичной неронки на MNIST. Кстати говоря, чтобы посмотреть как именно код работает на этом датасете, достаточно просто поменять первые строки с подгрузкой данных в тетрадку. \n",
    "\n",
    "\n",
    "![ ](https://raw.githubusercontent.com/FUlyankin/neural_nets_econ/master/2019/sem_6_pic/MNIST_error.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 3. Стреляем себе в ногу\n",
    " \n",
    "* Давайте разберём на Keras несколько архитектур. Попытайтесь понять что именно с ними не так. \n",
    "* Упражнения позаимствованы [из нескольких ШАДОвских семинаров по Keras.](https://github.com/yandexdataschool/Practical_DL/blob/master/week03_convnets/other_frameworks/how_to_shoot_yourself_in_the_foot_with_cnn.ipynb)\n",
    "\n",
    "#### a) Задача регрессии. Предсказываем цены на недвижимость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([39]))\n",
    "model.add(L.BatchNormalization())\n",
    "model.add(L.Dense(128, kernel_initializer=keras.initializers.zeros()))\n",
    "model.add(L.Dense(128, kernel_initializer=keras.initializers.zeros()))\n",
    "model.add(L.Dense(1))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  б) Классификация картинок, например, fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([28, 28, 1]))\n",
    "model.add(L.Conv2D(filters=512, kernel_size=(3, 3)))\n",
    "model.add(L.Activation('relu'))\n",
    "model.add(L.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(L.Flatten())\n",
    "model.add(L.Dense(100))\n",
    "model.add(L.Activation('softmax'))\n",
    "model.add(L.Dropout(0.1))\n",
    "model.add(L.Dense(10))\n",
    "model.add(L.Activation('softmax'))\n",
    "model.add(L.Dropout(0.1))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### в) И снова fashion MNIST, но теперь мы знаем, что размер картинки $100 \\times 100$ пикселей\n",
    "\n",
    "Если попробовать скомпилировать эту сетку, вылезет ошибка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([100, 100, 3]))\n",
    "\n",
    "for filters in [32, 64, 128, 256]:\n",
    "    model.add(L.Conv2D(filters, kernel_size=(5, 5)))\n",
    "    model.add(L.Conv2D(filters, kernel_size=(1, 1)))\n",
    "    model.add(L.MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(L.Activation('relu'))\n",
    "    model.add(L.BatchNormalization())\n",
    "\n",
    "model.add(L.Flatten())\n",
    "\n",
    "model.add(L.Dense(100, activation='relu'))\n",
    "model.add(L.Dropout(0.5))\n",
    "model.add(L.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
