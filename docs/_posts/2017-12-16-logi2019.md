---
title: 'Логи семинаров 2019'

layout: nil
---

* [Форма для сдачи домашек](https://docs.google.com/forms/d/e/1FAIpQLSfy0CaLlKLmFYlrv8MCCkW9pO2eA4bSbTIVxNjW6CysgkowSQ/viewform)

### Домашки

* [Домашка номер один,](https://nbviewer.jupyter.org/github/FUlyankin/neural_nets_econ/blob/master/2019/sem_1/HW1.ipynb) а также [датасет](https://github.com/FUlyankin/neural_nets_econ/blob/master/2019/sem_1/walmart.csv) к ней.
* [Домашка номер два,](https://nbviewer.jupyter.org/github/FUlyankin/neural_nets_econ/blob/master/2019/sem_2/HW2_gradient.ipynb) про градиентный спуск. [Дополнительное задание про эксперименты](https://nbviewer.jupyter.org/github/FUlyankin/neural_nets_econ/blob/master/2019/sem_2/Keras_SGD_experiments.ipynb) в конце семинарской тетрадк.

### Посиделка 3 (26 сентября): back-propagation

* [Ручные задачи](https://github.com/FUlyankin/neural_nets_econ/blob/master/2019/sem_3/tasks_3.pdf) к семинару
* [Решение backprop](https://github.com/FUlyankin/neural_nets_econ/blob/master/2019/sem_3/backprop.pdf) и [матричной части.](https://github.com/FUlyankin/neural_nets_econ/blob/master/2019/sem_3/matrix_diff.pdf) Лучше всего смотреть конспект. На семинарах мы записали всё лучше, чем в моём конспекте.

__Ещё материалы:__

* [Андрей Карпатый читает лекцию о backprop,](https://www.youtube.com/watch?v=59Hbtz7XgjM) и пишет о нём [в посте](http://cs231n.github.io/optimization-2/)
* [Конспект Жени Соколова](https://github.com/esokolov/ml-course-hse/blob/master/2017-fall/seminars/sem02-linregr-part1.pdf) про матричное диффириенцирование, [в репозитории](https://github.com/esokolov/ml-course-msu) много других конспектов
* [Задачник по ML Демешева,](https://github.com/bdemeshev/mlearn_pro/blob/master/mlearn_pro.pdf) часть задач на диффириенцирование из него
* [Матричный Coock book](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) с производными и вообще
* [Калькулятор матричных производных](http://www.matrixcalculus.org/)

### Посиделка 2 (19 сентября): градиентные спуски

* [Хочу всю папку с семинаром](https://github.com/FUlyankin/neural_nets_econ/raw/master/2019/sem_2/sem_2.zip)
* [Презентация с лекцией](https://github.com/FUlyankin/neural_nets_econ/blob/master/2019/sem_2/nn_slides_2.pdf)
* [Ручные задачи к семинару](https://github.com/FUlyankin/neural_nets_econ/blob/master/2019/sem_2/tasks_2.pdf)
* [Тетрадка с экспериментами на градиентный спуск](https://nbviewer.jupyter.org/github/FUlyankin/neural_nets_econ/blob/master/2019/sem_2/Keras_SGD_experiments.ipynb)
* [Вектор y](https://github.com/FUlyankin/neural_nets_econ/blob/master/2019/sem_2/y_cat.csv) и [матрица X](https://github.com/FUlyankin/neural_nets_econ/blob/master/2019/sem_2/X_cat.csv)
* [Блокнот с предобработкой данных](https://github.com/FUlyankin/neural_nets_econ/tree/master/2019/sem_2/original_cats) как дополнение



### Посиделка 1 (12 сентября): введение

* [Хочу всю папку с семинаром](https://github.com/FUlyankin/neural_nets_econ/raw/master/2019/sem_1/sem_1.zip)
* [Презентация с лекцией](https://github.com/FUlyankin/neural_nets_econ/blob/master/2019/sem_1/nn_slides_1.pdf)
* [Ручные задачи к семинару](https://github.com/FUlyankin/neural_nets_econ/blob/master/2019/sem_1/tasks_1.pdf)
* [Тетрадка с введением в Keras](https://nbviewer.jupyter.org/github/FUlyankin/neural_nets_econ/blob/master/2019/sem_1/sem1_keras_intro.ipynb)
