---
title: 'Идеология курса'

layout: nil
---

## Призыв

Добро пожаловать на страничку курса "Нейронки для экономистов и вообще". Чувствуй себя как дома.

> Нашёл на этой страничке ошибку? Нашёл какой-то ультраполезный ресурс? Придумал какое-то интересное задание для семинара? Есть конструктивная критика? Не молчи, напиши мне об этом на почту filfonul@gmail.com, в Telegram (@Ppilif) или [Вконтакте](https://vk.com/ppilif).

## Правила получения ништяков

Будет около 8 домашек. В сумме за них можно получить более 200 баллов. Если ты набрал 100 баллов, получаешь оценку 10. Задания делаются в командах по два человека.


## Идеология курса

Показать, что никакого искусственного интеллекта не существует. Нейросетка — это просто ансамбль из регрессий. Дать понять на каком уровне развития сейчас находится эта область машинного обучения и когда ждать нормальный искуственный интеллект, который всех поработит ну или хотябы будет присылать терминаторов. Показать различные архитектуры и экономические задачи, к решению которых их можно приложить.

Курс идёт 12 недель. Смотрим слайды, решаем на доске задачи, пишем код в python. В качестве фрэймворка для работы используем связку Tensorflow и Keras. Почему? Потому что они во всех компаниях в продакшене, а pytorch нет.

## Agenda

Прямо на первой паре мы научим свою первую нейросеть! Зачем тянуть? Это же легко! Потом мы несколько пар будем пытаться понять как всё устроено под капотом и как нейронки учатся. Потом мы поговорим про разные улучшалки и пойдём по разным видам нейросеток.

1. История, введение. От регрессии к нейросетке. Учим свою первую сеть не отходя от кассы.
2. Сетку в прошлый раз обучили? Давайте начнём понемногу разбираться что это было. Говорим откуда берутся функции потерь, обсуждаем 50 оттенков градиентного спуска. Ещё больше работы в Keras.
3. Матричные производные. Делаем руками backpropagation. Начинаем писать свою нейронку в numpy.
4. Какими бывают функции активации? Подробнее про Dropout. Заканчиваем с backpropagation. Вводимся в Tensorflow (наканецта).
5. Эвристики для обучения нейросетей. Инициализация. Нормализация по батчам.
6. Свёртка. Про то как нейросети видят картинки.
7. Воруем чужие веса. Локализация, сегментация, перенос стиля.
8. Автокодировщики, генеративные сетки.
9. Анализ текстов. Как научить компьютер читать? Что такое эмбединги?
10. Собираем две пары супер-архитектуру!
11. Временные ряды. Рекуррентные сети. Char-RNN.Генерируем новый фэйковые новости.
12. seq2seq сетки и автопереводы. Обучение с подкреплением.

Ещё варианты: байесовские методы и их скрещивание с нейронками. Что такое частичное обучение и как делать разметки?
