# Алгоритм обратного распространения ошибки

__Материалы с семинара:__

* [Тетрадка с экспериментами](https://github.com/FUlyankin/neural_nets_econ/blob/master/sem04_backprop/Keras_SGD_experiments_sem.ipynb) на градиентный спуск, [данные](https://github.com/FUlyankin/neural_nets_econ/blob/master/sem04_backprop/X_cat.csv), ещё [данные](https://github.com/FUlyankin/neural_nets_econ/blob/master/sem04_backprop/y_cat.csv)
* [Задачки на алгоритм обратного распространения ошибки](https://github.com/FUlyankin/neural_nets_econ/blob/master/sem04_backprop/tasks_04_backprop.pdf)
* [Прошлогоднее решение](https://github.com/FUlyankin/neural_nets_econ/blob/master/sem04_backprop/backprop.pdf) этих задачек
* Код, который успели написать за семинар для домашки

__Что можно поделать:__

* Дорешать ручные задачи из листочков. Всё, что не сможете решить, в следующий раз разберём.
* Собрать свою [собственную реализацию нейронной сетки](https://github.com/FUlyankin/neural_nets_econ/tree/master/sem04_backprop/HW3_own_neural_network) (начали делать её в конце семинара)

__Ещё материалы:__

* [Видос с бэкпропом за 10 минут](https://www.youtube.com/watch?v=Ilg3gGewQ5U)
* [Андрей Карпатый читает лекцию о backprop,](https://www.youtube.com/watch?v=59Hbtz7XgjM) и пишет о нём [в посте](http://cs231n.github.io/optimization-2/)
* Ссылка на лекцию Андрея с курсеры
* [Лекции Deep learning на пальцах -](https://dlcourse.ai/) отличные видосы понятным языком
