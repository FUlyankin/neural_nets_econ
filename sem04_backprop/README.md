# Алгоритм обратного распространения ошибки

__Материалы с семинара:__

* Тетрадка с экспериментами на градиентный спуск, данные
* Задачки на алгоритм обратного распространения ошибки
* Прошлогоднее решение этих задачек
* Код, который успели написать за семинар для домашки

__Что можно поделать:__

* Дорешать ручные задачи из листочков. Всё, что не сможете решить, в следующий раз разберём.
* Собрать свою собственную реализацию нейронной сетки (начали делать её в конце семинара)

__Ещё материалы:__

* [Видос с бэкпропом за 10 минут](https://www.youtube.com/watch?v=Ilg3gGewQ5U)
* [Андрей Карпатый читает лекцию о backprop,](https://www.youtube.com/watch?v=59Hbtz7XgjM) и пишет о нём [в посте](http://cs231n.github.io/optimization-2/)
* Ссылка на лекцию Андрея с курсеры
* [Лекции Deep learning на пальцах -](https://dlcourse.ai/) отличные видосы понятным языком
